<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Defactify 2 Workshop</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<style>
		p,i,li{
			color: black;
			/* font-size: 15px; */
		}
		.posts > article{
			width: 40%;
		}
		img{
			object-fit:contain;
			/* transform: scale(0.8); */
			width: auto;
 			height: 400px;
		}
		h2{
			text-align: center !important;
			text-transform: uppercase;
			
		}
		.major{
			text-align: center;
			
		}
		html{
			scroll-behavior: smooth;
		}
	

	
	
	</style>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Defactify 2</strong> Workshop</a>
									<ul class="icons">
										<li><a href="./factify.html" ><span class="label">Factify 2.0</span></a></li>
										<li><a href="./Memotion.html" ><span class="label">Memotion 3.0</span></a></li>
									</ul>
								</header>

							<!-- Content -->
								<section >
								
									<div style="background: url('https://aiisc.ai/defactify/img/background.gif');">
										<header class="main" style="text-align: center;">
											<span class="image main"><img src="https://aiisc.ai/defactify/img/banner_high_resolution_crop_2.png" alt="" /></span>
											
												<div>
													<h1 style="color: #fff;"><a href="https://aaai.org/Conferences/AAAI-23/" target="_blank" rel="noopener noreferrer">@ AAAI 2023</a>  </h1>
												<h2 style="color: #fff;">Second Workshop on ​Multimodal Fact Checking and Hate Speech Detection <br>
													February, 2023</h2>
												</div>
												
											</header>
									</div>
									
									<!-- <p>Donec eget ex magna. Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fergiat. Pellentesque in mi eu massa lacinia malesuada et a elit. Donec urna ex, lacinia in purus ac, pretium pulvinar mauris. Curabitur sapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit.</p>
									<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis dapibus rutrum facilisis. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Etiam tristique libero eu nibh porttitor fermentum. Nullam venenatis erat id vehicula viverra. Nunc ultrices eros ut ultricies condimentum. Mauris risus lacus, blandit sit amet venenatis non, bibendum vitae dolor. Nunc lorem mauris, fringilla in aliquam at, euismod in lectus. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. In non lorem sit amet elit placerat maximus. Pellentesque aliquam maximus risus, vel sed vehicula.</p>
									<p>Interdum et malesuada fames ac ante ipsum primis in faucibus. Pellentesque venenatis dolor imperdiet dolor mattis sagittis. Praesent rutrum sem diam, vitae egestas enim auctor sit amet. Pellentesque leo mauris, consectetur id ipsum sit amet, fersapien risus, commodo eget turpis at, elementum convallis elit. Pellentesque enim turpis, hendrerit tristique lorem ipsum dolor.</p> -->

									<hr class="major" />
									<header class="major" id="about">
									<h2 >ABOUT THE WORKSHOP</h2>
									</header>
									<p>
										Combating fake news is one of the burning societal crisis. It is difficult to expose false claims before they create a lot of damage. Automatic fact/claim verification has recently become a topic of interest among diverse research communities. Research efforts and datasets on text fact verification could be found, but there is not much attention towards multimodal or cross-modal fact-verification. This workshop will encourage researchers from interdisciplinary domains working on multimodality and/or fact checking to come together and work on multimodal (images, memes, videos) fact checking. At the same time, multimodal hate speech detection is an important problem but has not received much attention. Lastly, learning joint modalities his of interest to both Natural Language Processing (NLP) and Computer Vision (CV) forums.
									</p>
									<p>
										Link to previos year workshop : <a href="https://aiisc.ai/defactify/" target="_blank" rel="noopener noreferrer">Defactify @ AAAI 2022</a>
									</p>

									<h4>Important News Datasets Released:</h4>
									<h4>Factify 2</h4>
									<span>Colab: </span><a href="https://codalab.lisn.upsaclay.fr/competitions/8275" target="_blank" rel="noopener noreferrer">https://codalab.lisn.upsaclay.fr/competitions/8275</a>
									<br>
									<span>Form:</span><a href="https://forms.gle/L43vLWdYX3gGMTnV" target="_blank">https://forms.gle/L43vLWdYX3gGMTnV</a>
									<br>
									<br>
									<h4>Memotion 3</h4>
									<span>Dataset: </span><a href="https://drive.google.com/drive/folders/19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw?usp=sharing" target="_blank" rel="noopener noreferrer">https://drive.google.com/drive/folders/19yaav8ORSVj9DeJUaHKq1H3HtVnkClBw?usp=sharing</a>
									<br>
									<span>Form:</span><a href="https://forms.gle/gHt35gHEpgBtdmA7A" target="_blank">https://forms.gle/gHt35gHEpgBtdmA7A</a>
									
									<br>
									<br>
									<p>
										 During the last decade, both the field of studies - NLP and CV have made significant progress due to the success strories of neural network. Mutimodal tasks like visual question-answering (VQA), image captioning, video captioning, caption based image retrieval, etc. started getting into the main spotlight either in NLP/CV forums. Mutimodality is the next big leap for the AI community. De-Factify is a specified forum to discuss on multimodal fake news, and hate speech related challenges. We also encourage discussion on multimodal tasks in general.

									</p>

									<div>
										<ol>
											<li>
												<h4>Multi-Modal Fact Checking:</h4>
												<p>
													 Social media for news consumption is double edged sword. On the one hand, its low cost, easy access and rapid circulation of information lead people to consume news from social media. On the other hand, it enables the wide spread of fake news, i.e., low quality news with the false information. It affects everyone including government, media, individual, health, law and order, and economy. Therefore, fake news detection on social media has recently become an appealing research topic. We encourage solution to fake news like automated fact checking at scale, early detction of fake news etc.
												</p>



												<section>
													<!-- <header class="major">
														<h2>Examples</h2>
													</header> -->
													<div class="posts">
														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/trump_osama.png" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>The image purportedly shows US President Donald Trump in his younger days, shaking hands with global terrorist Osama Bin Laden. It had gone viral during the 2020 US presidential election. The picture also has a quote superimposed on it, praising Laden, which is attributed to Trump.</i>
															
														</article>

														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/baiden_corona.png" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>US President Joe Biden has announced that Americans who have not taken Covid vaccines will be put in quarantine camps and detained indefinitely till they take their shots. - this is absolutely a false claim.</i>
															
														</article>

														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/modi_namaz.png" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>A morphed picture of Prime Minister Narendra Modi is going viral on social platforms like Facebook and WhatsApp. Narendra Modi on July 11 was in Turkmenistan where he visited the Mausoleum of the First President of Turkmenistan, in Ashgabat. A picture was clicked during his visit in which Narendra Modi is seen standing with other religious and political leaders of Turkmenistan. While those leaders are seen raising their hands for dua (Islamic way of prayer), Modi is standing folding his hand. A morphed picture of the event is being shared on social media.</i>
															
														</article>
														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/pfizer_ceo.png" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>Several people are making a claim on their social media accounts that the CEO of Pfizer had to cancel a planned trip to Israel because he was not fully vaccinated. - the claim is not true.</i>
															
														</article>	
													</div>
												</section>
				

											</li>
											<li>
												<h4>
													Multi-Modal Hate-Speech
												</h4>
												<p>
													Hate speech is defined as speech (or any form of expression) that expresses (or seeks to promote, or has the capacity to increase) hatred against a person or a group of people because of a characteristic they share, or a group to which they belong. Twitter develops this definition in its hateful conduct policy as violence against or directly attack or threaten other people on the basis of race, ethnicity, national origin, sexual orientation, gender, gender identity, religious affiliation, age, disability, or serious disease. We encourage works that help in detection of Multi-Modal Hate-Speech.
												</p>
												<section>
													<!-- <header class="major">
														<h2>Examples</h2>
													</header> -->
													<div class="posts">
														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/hate.jpg" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>A simple image of few candies on a table. A set of candies are multicolored, while the others are black. The embeded text has a sarcastic twist to portray how blacks should be excluded from a so-called `perfect society'. This is an example of racist message.</i>
															
														</article>

														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/trump_muslim.jpeg" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>In this image former president Donalnd Trump is visible on a glof cart along with a Muslim man wearing a white middle-east dress. The embeded text is offensive towards muslim. The way it being written as if these are being said by Trump.</i>
															
														</article>

														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/jesus.png" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>In this image Jesus Christ is being depicted on a terrorist avatar - wearing sunglasses, having gun in one hand and riding on a Dinosaur. The tagline says "This is America" - it is offesive to both religious and towards the national image of America.</i>
															
														</article>
														<article>
															<a href="#" class="image"><img  src="https://aiisc.ai/defactify/img/lgbt.jpeg" alt="" /></a>
															<!-- <h3>Interdum aenean</h3> -->
															<i>This image showing a lady in a smiling face, whereas the text message depicts clear hate towards LGBT, rather gay to be very specific. The message clarifies sexual orientation is god's will.</i>
															
														</article>	
													</div>
												</section>
											</li>
										</ol>

									
									</div>
								</section>
								

									

										

									

									
								

								<section>
									<header class="major" id="call">
									<h2>CALL FOR SUBMISSIONS</h2>
								</header>
									<h3>REGULAR PAPER SUBMISSION</h3>

									<div style="text-align:center">
									</div>

									<h4>Topics of Interests</h4>
									<p>It is a forum to bring attention towards collecting, measuring, managing, mining, and understanding multimodal disinformation, misinformation, and malinformation data from social media. This workshop covers (but not limited to) the following topics: --</p>
									<ul>
										<li>
											Development of corpora and annotation guidelines for multimodal fact checking.
										</li>
										<li>
											Computational models for multimodal fact checking.
										</li>
										<li>
											Development of corpora and annotation guidelines for multimodal hate speech detection and classification.
										</li>
										<li>
											Computational models for multimodal hate speech detection and classification.
										</li>
										<li>
											Analysis of diffusion of Multimodal fake news and hate speech in social networks.
										</li>
										<li>
											Understanding the impact of the hate content on specific groups (like targeted groups).
										</li>
										<li>
											Fake news and hate speech detection in low resourced languages.
										</li>
										<li>
											Hate speech normalization.
										</li>
										<li>
											Case studies and/or surveys related to multimodal fake news or hate speech.
										</li>
										<li>
											Analyzing behavior, psychology of multimodal hate speech/ fake news propagator.
										</li>
										<li>
											Real world/ applied tool development for multimodal hate speech/fake news detection.
										</li>
										<li>
											Early detection of multimodal fake news/hate speech.
										</li>
										<li>
											Use of modalities other than text and images (like audio, video etc).
										</li>
										<li>
											Evolution of multi modal fake news and hate speech.
										</li>
										<li>
											Information extraction, ontology design and knowledge graph for multimodal hate speech and fake news.
										</li>
										<li>
											Cross lingual, code-mixed, code switched multimodal fake news/hate speech analysis.
										</li>
										<li>
											Computational social science.
										</li>
									</ul>

									<h4>Submission Instructions:</h4>
									<ul>
										<li><strong>Long papers: </strong> Novel, unpublished, high quality research papers. 10 pages excluding references.</li>
										<li><strong>Short papers:</strong> 5 pages excluding references.</li>
										<li><strong>Previously rejected papers:</strong>You can attach comments of previously rejected papers (AAAI, neurips) and 1 page cover letter explaining chages made.</li>
										<li><strong>Extended abstracts: </strong>2 pages exclusing references. Non archival. can be previously published papers or work in progress.</li>
										<li>All papers must be submitted via our EasyChair submission page.</li>
										<li>Regular papers will go through a double-blind peer-review process. Extended abstracts may be either single blind (i.e., reviewers are blind, authors have names on submission) or double blind (i.e., authors and reviewers are blind). Only manuscripts in PDF or Microsoft Word format will be accepted.</li>
										<li>Paper template: <a href="http://ceur-ws.org/Vol-XXX/CEURART.zip" target="_blank" rel="noopener noreferrer">http://ceur-ws.org/Vol-XXX/CEURART.zip </a> or <a href="https://www.overleaf.com/read/gwhxnqcghhdt" target="_blank" rel="noopener noreferrer">https://www.overleaf.com/read/gwhxnqcghhdt</a> </li>
									</ul>
									<!-- <h4>Important Dates (Round 1):</h4> -->
									<!-- <ul>
										<li> <strong>20 October 2022:</strong> &nbsp; Papers due at 11:59 PM UTC-12</li>
										<li><strong>20 November 2022:</strong> &nbsp;Notification of papers due at 11:59 PM UTC-12</li>
										<li> <strong>10 December 2022:</strong>&nbsp; Camera ready submission due of accepted papers at 11:59 PM UTC-12</li>
										<li> <strong>13-14 February 2023:</strong> &nbsp; Workshop</li>
									</ul> -->
									<!-- <h4>Important Dates (Round 2):</h4> -->
									<h4>Important Dates :</h4>

									<ul>
										<li>
											<strong>15 November 2022:</strong> Papers due at 11:59 PM UTC-12
										</li>
										<li>
											<strong>05 December 2022:</strong> Notification of papers due at 11:59 PM UTC-12
										</li>
										<li>
											<strong>20 December 2022:</strong> Camera ready submission due of accepted papers at 11:59 PM UTC-12
										</li>
										<li>
											<strong>13-14 February 2023:</strong> Workshop
										</li>
									</ul>
								</section>

								<section>

									<header class="major" id="shared">
										<h2>Shared tasks</h2>
									</header>

									<!-- <ol>
									 <li> <a href="http://" target="_blank" rel="noopener noreferrer" style="font-weight: 700;"> FACTIFY</a> - Multi-Modal Fact Verification. please visit this link for details.</li>
										<li>  <a href="http://" target="_blank" rel="noopener noreferrer" style="font-weight: 700;"> MEMOTION 2</a>  - Task on analysis of memes. please visit this link for details.</li>
									</ol> -->

									<div class="features" style="text-align: center;">
										
										<article>

											<!-- <span  style="background-image: url('https://aiisc.ai/defactify/img/factify_logo_nav.png');" ></span> -->
											
											
											<div class="content">
												<!-- <h3>FACTIFY 2</h3> -->
												<img src="https://aiisc.ai/defactify/img/factify_logo_nav.png" style="width:120px;height: 120px;"  alt="" srcset="">
												<p>Multi-Modal Fact Verification. please visit <a href="./factify.html" target="_blank" rel="noopener noreferrer">this link</a> for details.</p>
											</div>

											
											
										</article>
										<article>
											
											
											<div class="content">
												<!-- <h3>Memotion 3</h3> -->
												<img src="https://aiisc.ai/defactify/img/memotion_banner_nav.png" style="width:120px;height: 120px;"  alt="" srcset="">

												<p>Multi-Modal Fact Verification. please visit <a href="./Memotion.html" target="_blank" rel="noopener noreferrer">this link</a> for details.</p>
											</div>

										
										</article>
									
										</article>
									</div>
									
									<h4>FACTIFY 2 Important Dates:</h4>
									<ul>
										<li> <strong>13 October 2022:</strong>  Release of the training set</li>
										<li> <strong>17 November 2022:</strong>  Release of the test set</li>
										<li> <strong>23 November 2022:</strong>  Deadline for submitting the final results</li>
										<li> <strong>25 November 2022:</strong>  Announcement of the results</li>
										<li> <strong>5 December 2022:</strong>  System paper submission deadline (All teams are invited to submit a paper)</li>
										<li> <strong>12 December 2022:</strong>  Notification of system papers</li>
										<li> <strong>23 December 2022:</strong>  Camera ready submission</li>
									</ul>
									<h4>Memotion 2 Important Dates:</h4>
									<ul>
										<li> <strong>13 October 2022:</strong>  Release of the training set</li>
										<li> <strong>17 November 2022:</strong>  Release of the test set</li>
										<li> <strong>23 November 2022:</strong>  Deadline for submitting the final results</li>
										<li> <strong>25 November 2022:</strong>  Announcement of the results</li>
										<li> <strong>5 December 2022:</strong>  System paper submission deadline (All teams are invited to submit a paper)</li>
										<li> <strong>12 December 2022:</strong>  Notification of system papers</li>
										<li> <strong>23 December 2022:</strong>  Camera ready submission</li>
									</ul>

								</section>

								<section>
								<header class="major" id="awards">
									<h2>AWARDS</h2>
								</header>
								<h4>To be announced</h4>
									<!-- <ul>
										<li>
											<h4>Best paper</h4>
											<p>Team Yao at Factify 2022: Utilizing Pre-trained Models and Co-attention Networks for Multi-Modal Fact Verification.
												Wei-Yao Wang and Wen-Chih Peng.</p>
										</li>
										<li>
											<h4>Factify shared task winner</h4>
											<p>Logically at the Factify 2022: Multimodal Fact Verification.
												Jie Gao, Hella-Franziska Hoffmann, Stylianos Oikonomou, David Kiskovski and Anil Bandhakavi.</p>
										</li>
										<li>
											<h4>Memotion Task A winner</h4>
											<p>BLUE at Memotion 2.0 2022: You have my Image, my Text and my Transformer.
												Ana-Maria Bucur, Adrian Cosma and Ioan-Bogdan Iordache.</p>
										</li>
										<li>
											<h4>Memotion Task B winner</h4>
											<p>Little Flower at Memotion 2.0 2022 : Ensemble of Multi-Modal Model using Attention Mechanism in MEMOTION Analysis.
												Kim Ngan Phan, Guee-Sang Lee, Hyung-Jeong Yang and Soo-Hyung Kim.</p>
										</li>
										<li>
											<h4>Memotion Task C winner</h4>
											<p>Amazon PARS at Memotion 2.0 2022: Multi-modal Multi-task Learning for Memotion 2.0 Challenge.
												wang Gook Lee and Mingwei Shen.</p>
										</li>
									</ul> -->
								</section>

								<section>
									<header class="major" id="accepted">
									<h2>Accepted Papers</h2>
								</header>
									<h4>To be announced</h4>
								</section>
								<section>
									<header class="major" id="invited">
									<h2>Invited Talks</h2>
								</header>
									<div style="display: flex;flex-direction:column;gap:30px;">
											
											
										<div style="display: flex;justify-content:space-evenly;text-align: justify;">
												<div style="text-align: center;flex: 1;">
													<img src="https://andreasvlachos.github.io//assets/img/prof_pic.jpg" style="height: 150px;" alt="" />
													<h4>Dr. Andreas Vlachos</h4>
													<h4>Department of Computer Science and Technology <br> at the University of Cambridge</h4>
												</div>
												<div>
													<strong>NLP and ML Professor at University of Cambridge.</strong>
												<br>
												<strong>Creator of FEVER Dataset.</strong>
												<br>
												<strong>Organizer of Fake News Challenge.</strong>

												</div>
												
											</div>
											<hr>
											<div style="display: flex;justify-content:space-evenly;text-align: justify;">
												<div style="text-align: center;flex: 1;">
													
													<img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=DfXsKZ4AAAAJ&citpid=3" style="height: 150px;" alt="">

														<h4>Dr. Preslav Nakov</h4>
													<h4>Mohamed bin Zayed University of Artificial Intelligence <br> Masdar City, Abu Dhabi</h4>
													</div>
													
												
												<div>	
													<strong>Computer Scientist working on NLP.</strong> <br>
												<strong>Organizer of NLP for Internet Freedom (NLP4IF).</strong> <br>
												<strong>Organizer of OffensEval Task</strong>

												</div>
											
												
									</div>
											
									
			
									</div>

								</section>

								<section>
									<header class="major" id="chairs">
									<h2>
										ORGANIZING COMMITTEE CHAIRS
									</h2>
								</header>

								<div style="display: flex;flex-direction:column;gap:60px">
								
								<div>
									<h4 style="text-decoration:underline">Dr. Amitava Das:</h4>
									<div style="display: flex;">
										<div class="image" style="width: 30%;">
											<img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=HYpfhaEAAAAJ&citpid=4" style="height: 150px;" alt="">
											<br>
										   
										</div>
										<div style="width: 70%;">
											<p>Dr. Amitava Das is a Core Faculty & Research Associate Professor of the Artificial Intelligence Institute, at University of South Carolina. <br> <br>
												<strong>Research interests : </strong>Code-Mixing
												and Social Computing.
												<br> <br> <strong>Organizing Activities [selective] : </strong> 

												• Memotion @SemEval2020 • SentiMix @SemEval2020 • Computational Approaches to Linguistic Code-Switching  @LREC 2020  • CONSTRAINT @AAAI2021
												
												</p>
												<div>
													<b><a href="http://www.amitavadas.com/" target="_blank" rel="noopener noreferrer">Web ,</a></b>
										   <b><a href="https://scholar.google.co.in/citations?hl=en&user=HYpfhaEAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar,</a></b>	
										   <b><a href="mailto:amitava.das2@wipro.com" target="_blank" rel="noopener noreferrer">Email</a></b>
												</div>
										

										</div>

										
										</div>
									</div>

									<div>
										<h4 style="text-decoration:underline">Srijan Kumar:</h4>
										<div style="display: flex;">
											<div class="image" style="width: 30%;">
												<img src="https://faculty.cc.gatech.edu/~srijan/img/headshot-jan-2020.png" style="height: 150px;" alt="">
												<br>
											   
											</div>
											<div style="width: 70%;">
												<p>Srijan Kumar is an assistant professor of CSE at Georgia Tech. <br> <br>
													<strong>Research interests : </strong>Multi-X Misinformation and Malicious Actors: Multi-Platform, Multi-Modal, and Multi-Lingual
													<br> <br> 
													<!-- <strong>Organizing Activities [selective] : </strong>  -->
	
													<!-- • Memotion @SemEval2020 • SentiMix @SemEval2020 • Computational Approaches to Linguistic Code-Switching  @LREC 2020  • CONSTRAINT @AAAI2021 -->
													
													</p>
													<div>
														<b><a href="https://faculty.cc.gatech.edu/~srijan/" target="_blank" rel="noopener noreferrer">Web ,</a></b>
											   <b><a href="https://scholar.google.com/citations?user=kqfLNK8AAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar,</a></b>	
											   <b><a href="mailto:srijan@gatech.edu" target="_blank" rel="noopener noreferrer">Email</a></b>
													</div>
											
	
											</div>
	
											
											</div>
										</div>
									

									

									
									<div>
										<h4 style="text-decoration:underline">Dr. Manoj Chinnakotla:</h4>
	
											<div style="display: flex;">
												<div class="image" style="width: 30%;">
													<img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=74sJeNEAAAAJ&citpid=2" style="height: 150px;" alt="">
													<br>
												   
												</div>
												<div style="width: 70%;">
													<p>Manoj Chinnakotla is a principal
														applied scientist of AI research at Microsoft. <br> <br>
													<strong>Research interests : </strong>NLP, Information Retrieval, Machine Learning.
													</p>
													
													<div>
														<b><a href="https://www.linkedin.com/in/manoj-chinnakotla-32933419" target="_blank" rel="noopener noreferrer">Web ,</a></b>
												   <b><a href="https://scholar.google.co.in/citations?user=74sJeNEAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a></b>	
												  

													</div>
		
												</div>
											</div>
									</div>

									<div>
										<h4 style="text-decoration:underline">Dr. Amit Sheth:</h4>
	
											<div style="display: flex;">
												<div class="image" style="width: 30%;">
													<img src="https://aiisc.ai/defactify/img/committee/amitsheth.jpg" style="height: 150px;" alt="">
													<br>
													
												   
												</div>
												<div style="width: 70%;">
													<p>Dr. Amit Sheth is the founding Director of the Artificial Intelligence
														Institute, and a CSE Professor at
														University of South Carolina.
														<br><br>
													 <strong>Research interests : </strong>Knowledge
														Graph, NLP, Analysing Social
														Media
														<br><br>
														<strong>Organizing Activities [selective] : </strong> 
														• Cysoc2021 @ ICWSM2021 • Emoji2021 @ICWSM2021 • KiLKGC 2021 @KGC21
	
														<div>
															<b><a href="http://amit.aiisc.ai/" target="_blank" rel="noopener noreferrer">Web ,</a></b>
														   <b><a href="https://scholar.google.com/citations?user=2T3H4ekAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar,</a></b>	
														   <b><a href="mailto:amit@sc.edu" target="_blank" rel="noopener noreferrer">Email</a></b>
															</div>
													</p>
												
		
												</div>
											</div>
										</div>

									<div>
										<h4 style="text-decoration:underline">Dr. Asif Ekbal:</h4>
	
											<div style="display: flex;">
												<div class="image" style="width: 30%;">
													<img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=IAL_F04AAAAJ&citpid=4" style="height: 150px;" alt="">
													<br>
												   </div>
												<div style="width: 70%;">
													<p>Dr. Asif Ekbal is an Associate Professor of CSE at IIT Patna, India.
														<br> <br>
													<strong>Research interests : </strong> NLP, CodeMixing and Social Computing.
													<br> <br>
													<strong>Organizing Activities [selective] : </strong>  • CONSTRAINT @AAAI2021	
													</p>

													<div>
														<b><a href="https://www.iitp.ac.in/~asif/" target="_blank" rel="noopener noreferrer">Web ,</a></b>
												   <b><a href="https://scholar.google.co.in/citations?user=IAL_F04AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar,</a></b>	
												   <b><a href="mailto:asif.ekbal@gmail.com" target="_blank" rel="noopener noreferrer">Email</a></b>
												
													</div>
												
		
												</div>
											</div>
									</div>


									<div>
										<h4 style="text-decoration:underline">Parth Patwa</h4>
	
											<div style="display: flex;">
												<div class="image" style="width: 30%;">
													<img src="https://parthpatwa.github.io/assets/parth.jpg" style="height: 150px;" alt="">
													<br>
												   </div>
												<div style="width: 70%;">
													<p>Masters student at University of California Los Angeles (UCLA).
														<br> <br>
													<strong>Research interests : </strong> Natural Language Processing, Machine Learning, Social Computing, and Computer Vision.
													<br> <br>
													<!-- <strong>Organizing Activities [selective] : </strong>  • CONSTRAINT @AAAI2021	 -->
													</p>

													<div>
														<b><a href="https://parthpatwa.github.io/" target="_blank" rel="noopener noreferrer">Web ,</a></b>
												   <b><a href="https://scholar.google.com/citations?user=nlpQCpsAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar,</a></b>	
												   <b><a href="mailto:parthpatwa@g.ucla.edu" target="_blank" rel="noopener noreferrer">Email</a></b>
												
													</div>
												
		
												</div>
											</div>
									</div>




									
									
								</div>

										
								</section>

								<section>
									<header class="major" id="coordinators">
									<h2>ASSOCIATE ORGANIZERS</h2>
								</header>
									<div style="display: flex;justify-content:center;gap:100px">

									
									<!-- <div class="image" style="text-align: center;">
										<img src="https://aiisc.ai/defactify/img/committee/parth.jpg" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>Parth Patwa</strong>
										<br>
										<strong>UCLA, USA</strong>
									</div> -->
									<div class="image" style="text-align: center;">
										<img src="https://aiisc.ai/defactify/img/committee/aishwarya.png" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>AISHWARYA REGANTI</strong>
										<br>
										<strong>AMAZON ALEXA, USA</strong>
									</div>
									<div class="image" style="text-align: center;">
										<img src="https://aiisc.ai/assets/img/team/Megha.jpg" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>Megha Chakraborty</strong>
										<br>
										<strong>UNIVERSITY OF SOUTH CAROLINA, USA</strong>
									</div>

									

									

								</div>

								<div style="display: flex;justify-content:center;gap:100px;margin: 10vh 0;">

									<div class="image" style="text-align: center;">
									
										<img src="https://aiisc.ai/defactify/img/committee/shreyash.png" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>SHREYASH MISHRA</strong>
										<br>
										<strong>IIIT SRI CITY, INDIA</strong>
									</div>
	
									<div class="image" style="text-align: center;">
										<img src="https://aiisc.ai/defactify/img/committee/surya.jpg" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>S. SURYAVARDAN</strong>
										<br>
										<strong>IIIT SRI CITY, INDIA</strong>
									</div>

									<!-- <div class="image" style="text-align: center;">
										<img src="./images/SRIJAN.jpeg" style="height: 150px;margin: 0 auto;" alt="">
										<br>
										<strong>Srijan Chattopadhyay</strong>
										<br>
										<strong>ISI, KOLKATA, INDIA</strong>
									</div> -->

								</div>
							
								</section>
								<section>
									<header class="major">
										<h2>WEB CHAIR</h2>
										</header>
									<div style="display: flex;justify-content: center;">

									<div>
										
										<div class="image" style="text-align: center;">
											<img src="https://aiisc.ai/assets/img/team/Jinendra.jpg" style="height: 150px;margin: 0 auto;" alt="">
											<br>
											<strong>Jinendra Malekar</strong>
											<br>
											<strong>UNIVERSITY OF SOUTH CAROLINA, USA</strong>
										</div>

									</div>
								
								</div>

								</section>

								<section>
									<header class="major" id="contact">
										<h2>CONTACT US</h2>
										</header>

									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="mailto:amitava.santu@gmail.com"> amitava.santu@gmail.com</a></li>
										<li class="icon solid fa-envelope"><a href="mailto:parthpatwa@ucla.edu"> parthpatwa@ucla.edu</a></li>
										
									</ul>
								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<!-- <section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section> -->

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="#about" >ABOUT THE WORKSHOP</a></li>
										<li><a href="#call">CALL FOR SUBMISSIONS</a></li>

										<li><a href="#shared">SHARED TASKS</a></li>
										
										
										<li><a href="#awards">AWARDS</a></li>
										<li><a href="#accepted">ACCEPTED PAPERS</a></li>
									
										<li><a href="#invited">INVITED TALKS</a></li>
										<li><a href="#chairs">ORGANIZING COMMITTEE CHAIRS</a></li>
										<li><a href="#coordinators">ASSOCIATE ORGANIZERS</a></li>
										<li><a href="#contact">CONTACT US</a></li>

									</ul>
									<hr>
									<p>
										Link to previos year workshop : <a href="https://aiisc.ai/defactify/" target="_blank" rel="noopener noreferrer">Defactify @ AAAI 2022</a>
									</p>

									<br>
									<br>
									<a href="factify.html" style="font-size: 20px;"> 
										Factify 2.0
									</a>
									<br>
									<a href="Memotion.html" style="font-size: 20px;"> 
										Memotion 3.0
									</a>

								</nav>

				

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>