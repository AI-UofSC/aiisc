<!DOCTYPE html>
<html>
<head>

	<title>IRT-AI</title>
  <meta content="" name="description">
  <meta content="" name="keywords">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">


  <!-- Favicons -->
  <link href="assets/img/brain-logo.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">
  <style type="text/css">

@media (max-width: 3000px) { 

body{
  margin-top: 8%;
}


@media (max-width: 1600px) { 

body{
  margin-top: 8%;
}

  }

  @media (max-width: 1300px) { 

body{
  margin-top: 12%;
}

  }

@media (max-width: 1030px) { 

body{
  margin-top: 12%;
}

  }
  

@media (max-width: 770px) { 

body{
   
  margin-top: 15%;
}
  }
  @media (max-width: 545px) { 

body{
   
  margin-top: 22%;
}
  }

  @media (max-width: 415px) { 

body{
   
  margin-top: 28%;
}
  }

  @media (max-width: 376px) { 

body{
   
  margin-top: 32%;
}
  }


  @media (max-width: 360px) { 

body{
   
  margin-top: 32%;
}
  }


  @media (max-width: 320px) { 

body{
   
  margin-top: 36%;
}
  }

  
  @media (max-width: 282px) { 

body{
   
  margin-top: 42%;
}
  }

  	@media (max-width: 767.98px) { 

      .youtube-frame{
        width:100%; 
        height: 500px;
        border:5px solid #d9232d;
      }
  	 }

  	@media (min-width: 767.98px) { 
      .youtube{
        margin-left: 15%;

      }
      .youtube-frame{
        width:70%; 
        height: 500px;
        border:5px solid #d9232d;
      }

  	 }
    }
  </style>
</head>
<body>
  <header id="header" class="fixed-top d-flex align-items-center">
    <div class="container d-flex align-items-center">

      
      <h1 class="logo me-auto"><a href="index.html" class="logo me-auto"><img src="assets/img/brain-logo.png"  alt="" class="img-fluid"></a>&nbsp;&nbsp;IRT-AI</h1>
      <!-- Uncomment below if you prefer to use an image logo -->

      <nav id="navbar" class="navbar" class="shadow p-3 mb-5 bg-body rounded">
        <ul>
          <li><a href="index.html" >Overview</a></li>
          <li class="dropdown"><a href="#"><span>Areas</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="research.html" >Research</a></li>
              <li><a href="vision.html">AIISC Vision</a></li>
              <li><a href="discussion.html">Discussion Group</a></li>
              <li><a href="overviewFall.html" >Overview (Fall 2020)</a></li>
              <li><a href="dissertation.html">Dissertation</a></li>
            </ul>
          </li>
          <li ><a href="people.html"><span>People</span></i></a></li>
          <li><a href="projects.html">Projects</a></li>
          <li><a href="courses.html" >Courses</a></li>
          <li><a href="facility.html" >Facilities</a></li>
            <li class="dropdown"><a href="#"><span>Library</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="https://scholarcommons.sc.edu/aii_fac_pub/" target="_blank">Publications</a></li>
              <li><a href="showcase.html">Showcase</a></li>
              <li><a href="opensource/index.html">Opensource</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="#" class="active"><span>Events</span> <i class="bi bi-chevron-down"></i></a>
            <ul>
              <li><a href="workshop.html">Workshops</a></li>
              <li><a href="tutorials.html" class="active">Tutorials</a></li>
              <li><a href="Special.html">Special Issues</a></li>
              <li><a href="Atiisc.html">At AIISC</a></li>
             <li><a href="./aicamp24/base.html" target="_blank">AI Summer Camp</a></li>
              <li><a href="focus.html">Focus Group</a></li>



            </ul>
          </li>
          <!-- <li><a href="socs.html">Socs</a></li>  -->
          <li><a href="Joining.html"> Joining Us</a></li>
          <li><a href="reach.html">Reach Us</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->
    </div>
  </header>
  <div id="screen" class="container">

<!-- AAAI25 -->
<h3 style="margin:3% 0;color:#d9232d;">
  <a href="https://vr25.github.io/aaai25-hallucination-tutorial/" target="_blank" style="text-decoration: underline;">
    AAAI 2025 Tutorial : Hallucinations in Large Multimodal Models
  </a> 
  <i class='bx bx-link' style="font-size: 20px;"></i>
</h3>
<h5 style="margin:3% 0;color:#d9232d;">
  <strong>Date: February 26, 2025 | Philadelphia, Pennsylvania, USA</strong>
</h5>
<p>
  Large Language Models (LLMs) have made significant strides in generating human-like text, but their tendency to hallucinate—producing factually incorrect or fabricated information—remains a pressing issue. This tutorial provides a comprehensive exploration of hallucinations in LLMs, introducing participants to the key concepts and challenges in this domain. We will cover the types of hallucination, including Factual Mirage and Silver Lining, and present the latest approaches for benchmarking, detection, and mitigation. The motivation for understanding hallucination is particularly critical from a multimodal standpoint, as Vision-Language Models (VLMs) can exacerbate the problem by blending hallucinated text with misleading images or video. The tutorial will offer practical techniques to reduce hallucinations using both black-box and gray-box methods. Designed for researchers and professionals in generative AI, this tutorial bridges the gap between emerging research and practical solutions, providing attendees with valuable insights and tools to enhance the factual accuracy of LLM outputs. Participants will gain a deeper understanding of the complexities surrounding LLM hallucination and be equipped with strategies to drive future innovations in the field.
</p>
<p>
  For more information, visit 
  <a href="https://vr25.github.io/aaai25-hallucination-tutorial/">Our Website</a>
</p>
<!-- AAAI25 end -->

<!-- LREC-COLING24 -->
<h3 style="margin:3% 0;color:#d9232d;">
  <a href="https://vr25.github.io/lrec-coling-hallucination-tutorial/" target="_blank" style="text-decoration: underline;">
    LREC-COLING 2024 Tutorial : Hallucination in Large Language Models
  </a> 
  <i class='bx bx-link' style="font-size: 20px;"></i>
</h3>
<h5 style="margin:3% 0;color:#d9232d;">
  <strong>Date: May 25, 2024 | Torino, Italy</strong>
</h5>
<p>
  In the fast-paced domain of Large Language Models (LLMs), the issue of hallucination is a prominent challenge. Despite continuous endeavors to address this concern, it remains a highly active area of research within the LLM landscape. Grasping the intricacies of this problem can be daunting, especially for those new to the field. This tutorial aims to bridge this knowledge gap by introducing the emerging realm of hallucination in LLMs. It will comprehensively explore the key aspects of hallucination, including benchmarking, detection, and mitigation techniques. Furthermore, we will delve into the specific constraints and shortcomings of current approaches, providing valuable insights to guide future research efforts for participants.
</p>
<p>
  For more information, visit 
  <a href="https://vr25.github.io/lrec-coling-hallucination-tutorial/">Our Website</a>
</p>
<!-- LREC-COLING24 end -->


<!-- AAMAS25 -->
<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/tutorials/AAMAS_Tutorial_Multiagent_CoPilot_in_Industrial_AI_Applications/" target="_blank" style="text-decoration: underline;">AAMAS 2025 Tutorial : Multiagent CoPilot in Industrial AI Applications</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
  <h5 style="margin:3% 0;color:#d9232d;"><strong>Date: May 19-20, 2025 | Detroit, Michigan, USA</strong></h5>
  <p>
  In the era of smart automation and digital transformation, achieving efficiency, precision, and adaptability is essential for industries to remain competitive. Sectors, including manufacturing, supply chain and logistics, healthcare, finance, and retail, face significant challenges in deploying Artificial Intelligence (AI) solutions tailored to their unique needs, particularly in critical, resource-constrained applications. According to Gartner’s 2024 Hype Cycle for Artificial Intelligence, composite AI, which integrates techniques like machine learning, knowledge graphs, and rule-based systems, is becoming foundational for industries, enhancing predictions, decisions, and scalability across complex environments. The complexity of real-world systems requires Industrial AI solutions to be customizable to business needs, compact for efficient deployment on resource-constrained devices, and agile to adapt to changing requirements. By being neurosymbolic, such solutions integrate data, knowledge, and human expertise to create robust, explainable, and trustworthy AI that supports planning and reasoning. In this tutorial, we will introduce Multiagent CoPilot for Industrial AI applications focusing on the primary use case of manufacturing (offering requirements, data, knowledge, human expertise). The use cases we will describe are inspired by collaborations with, or similar efforts at Bosch, Hewlett Packard Enterprise, Siemens, and others. AAMAS audience will learn about human-in-the-loop CoPilots as we explore how multiagent coordination, collaboration, and decision-making can enhance the functionality of industrial AI models. With our primary use case, we will demonstrate how to address the unique challenges faced by the manufacturing industry, from improving operational efficiency to enhancing adaptability in critical tasks. However, the knowledge and insights gained from this tutorial are applicable and generalizable to various industries, like transportation and healthcare, offering valuable perspectives for researchers and professionals across domains seeking to adopt these technologies in real-world applications.
</p>
  <p>For more information, visit <a href="https://aiisc.ai/tutorials/AAMAS_Tutorial_Multiagent_CoPilot_in_Industrial_AI_Applications/">Our Website</a>
  </p> 
<!-- AAMAS25 end -->

<!--AAAI25-->
    <h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/aaai25/AAAI-Lab-Rare-Event-Prediction/" target="_blank" style="text-decoration: underline;">AAAI'25-Lab: Developing Explainable Multimodal AI Models With Hands-on Lab on the Life-cycle of Rare Event Prediction in Manufacturing</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
  <h5 style="margin:3% 0;color:#d9232d;"><strong>Date: February 25-26, 2025 | Philadelphia, Pennsylvania, USA</strong></h5>
  <p>
  In the age of Industry 4.0 and smart automation, unplanned downtime costs industries over $50 billion annually. Even with preventive maintenance, industries like automotive lose more than $2 million per hour due to downtime caused by unexpected or “rare” events. The extreme rarity of these events makes their detection and prediction a significant challenge for AI practitioners. Factors such as the lack of high-quality data, methodological gaps in the literature, and limited practical experience with multimodal data exacerbate the difficulty of rare event detection and prediction. This lab will provide hands-on experience to learn how to address these challenges by exploring the entire lifecycle of rare event analysis, from data generation and preprocessing to model development and evaluation. Developing a process ontology for user-level/application-level/domain-specific explanations will also be demonstrated. Participants will be introduced to the limited publicly available datasets and, will gain hands-on experience with a newly developed multi-modal dataset designed explicitly for rare event prediction. Through several hands-on sessions, participants will learn how to generate such a high-quality dataset and the practical use of this dataset to develop rare event prediction models. Those interested in developing AI models involving diverse multimodal data for other applications will also benefit from participation. The learning from this lab will also be relevant to other domains and applications, such as healthcare, finance, and energy, where predictive maintenance can help prevent costly failures in complex systems. Participants will gain valuable insights and skills transferrable across industries where rare events impact operational efficiency and require advanced predictive techniques.
  </p>
  <p>For more information, visit <a href="https://aiisc.ai/aaai25/AAAI-Lab-Rare-Event-Prediction/">Our Website</a>
  </p>    
<!--AAAI25 end-->

  <h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/smbd24" target="_blank" style="text-decoration: underline;">IEEE BigData 2024: Neuro-Symbolic AI for Deep Analysis of Social Media Big Data</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
  <h5 style="margin:3% 0;color:#d9232d;"><strong>Date: December 15-18, 2024 | Washington, DC, USA</strong></h5>
  <p>
    This tutorial introduces a neuro-symbolic AI framework to analyze big data from social media platforms. Integrating human-curated knowledge through symbolic AI with the pattern recognition capabilities of neural networks enhances the adaptability and efficiency of traditional neural network approaches. Knowledge-guided zero-shot learning techniques enable swift adaption to new linguistic contexts and emerging events [6]. Participants will explore how to design, develop, and utilize these models in specific domains, such as public health surveillance that require dynamic adaptation to new terminologies. The tutorial aims to equip attendees with practical skills and a deep understanding of how to apply neuro-symbolic AI to manage and analyze large-scale social media datasets effectively.
  </p>
  <p>For more information, visit <a href="https://aiisc.ai/smbd24/">Our Website</a>
  </p>   

	  <h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/empwrbd24" target="_blank" style="text-decoration: underline;">IEEE BigData 2024: Knowledge-driven Processes for Big Data Management and Applications</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
  <h5 style="margin:3% 0;color:#d9232d;"><strong>Date: December 15-18, 2024 | Washington, DC, USA</strong></h5>
  <p>
    The unparalleled volume of data generated has heightened the need for approaches that can manage and translate them into actionable insights. While the contemporary data-driven and generative systems are popular for handling large volume of changing and diverse data, they are not silver bullets due to the inherent lack of knowledge grounding. The emerging use of knowledge-driven processes have surfaced as compelling approaches for leveraging external knowledge and structured representation to complement the shortcomings within data-driven systems. Such processes which while exploiting data, also use extensive knowledge in the form of Knowledge Graphs (KGs). In this tutorial, we will introduce and provide interactive hands-on and lab-oriented sessions on the knowledge-driven processes for big data management and applications using realworld datasets ranging from structured, semi-structured, and unstructured formats. Specifically we will use the EMPWR platform for creating and maintaining large KGs and demonstrate recent innovations in three concrete real world use-cases: (i) development of a pharmaceutical KG with over 6M triples, 1.5M nodes, and 3000 relation types; (ii) development of a suite of large scale KGs with 10M+ triples, 2M+ entities, and 19 relations from real-world driving scenes and their use in machine perception tasks; and (iii) AI pipelines recommender system with KG consisting of 78M triples, 8M nodes, and 25M relations.
  </p>
  <p>For more information, visit <a href="https://aiisc.ai/empwrbd24/">Our Website</a>
  </p> 

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://kauroy1994.github.io/ISWC-2024-Tutorial-Neurosymbolic-Customized-and-Compact-CoPilots/" target="_blank" style="text-decoration: underline;">Neurosymbolic Customized and Compact CoPilots</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<p>
Large Language Models (LLMs) are credible with open-domain interactions such as question answering, summarization, and explanation generation. LLM reasoning is based on parametrized knowledge, and as a consequence, the models often produce absurdities and inconsistencies in outputs (eg, hallucinations and confirmation biases)[2]. In essence, they are fundamentally hard to control to prevent off-the-rails behaviors, are hard to fine-tune, customize for tailored needs, prompt effectively (due to the “tug-of-war” between external and parametric memory), and extremely resource-hungry due to the enormous size of their extensive parametric configurations. Thus, significant challenges arise when these models are required to perform in critical applications in domains such as healthcare and finance, that need better guarantees and in turn, need to support grounding, alignment, and instructibility. AI models for such critical applications should be customizable or tailored as appropriate for supporting user assistance in various tasks, compact to perform in real-world resource-constraint settings, and capable of controlled, robust, reliable, interpretable, and grounded reasoning (grounded in rules, guidelines, and protocols). This special session explores the development of compact, custom neurosymbolic AI models and their use through human-in-the-loop co-pilots for use in critical applications.



</p>    

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/causalai/" target="_blank" style="text-decoration: underline;">Lecture-style Tutorial: Causal AI for web and health care</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<p>
  Improving the performance and explanations of ML algorithms is a priority for adoption by humans in the real world. In critical domains such as healthcare, such technology has significant potential to reduce the burden on humans and considerably reduce manual assessments by providing quality assistance at scale. In today’s data driven world, artificial intelligence (AI) systems are still experiencing issues with bias, explainability, and human-like reasoning and interpretability. Causal AI is the technique that can reason and make human like choices making it possible to go beyond narrow Machine learning based techniques and can be integrated into human decision making. It also offers intrinsic explainability, new domain adaptability, bias free predictions and works with datasets of all sizes. In this tutorial of type lecture style we detail how a richer representation of causality in AI systems using a knowledge graph (KG) based approach is needed for intervention and counterfactual reasoning (Figure 1), how do we get to model based and domain explainability, how causal representations helps in web and health care.



</p>

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/neurone/" target="_blank" style="text-decoration: underline;">Neuro-symbolic AI for mental healthcare</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<p>
  Artificial Intelligence (AI) systems for mental healthcare (MHCare) have been ever-growing after realizing the importance of early interventions for patients with chronic mental health (MH) condi- tions. Social media (SocMedia) emerged as the go-to platform for supporting patients seeking MHCare. The creation of peer-support groups without social stigma has resulted in patients transitioning from clinical settings to SocMedia supported interactions for quick help. Researchers started exploring SocMedia content in search of cues that showcase correlation or causation between different MH conditions to design better interventional strategies. User-level Classification-based AI systems were designed to leverage diverse SocMedia data from various MH conditions, to predict MH condi- tions. Subsequently, researchers created classification schemes to measure the severity of each MH condition. Such ad-hoc schemes, engineered features, and models not only require a large amount of data but fail to allow clinically acceptable and explainable reasoning over the outcomes. To improve Neural-AI for MHCare, infusion of clinical symbolic knowledge that clinicans use in decision mak- ing is required. An impactful use case of Neural-AI systems in MH is conversational systems. These systems require coordination between classification and generation to facilitate humanistic con- versation in conversational agents (CA). Current CAs with deep language models lack factual correctness, medical relevance, and safety in their generations, which intertwine with unexplainable statistical classification techniques. 
</p>

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://kl4ad.github.io/2022/" target="_blank" style="text-decoration: underline;"> Knowledge-infused Learning for Autonomous Driving</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<p>Autonomous Driving (AD) is considered as a testbed for tackling many hard AI problems. Despite the recent advancements in the field, AD is still far from achieving full autonomy due to core technical problems inherent in AD. The emerging field of neuro-symbolic AI and the methods for knowledge-infused learning are showing exciting ways of leveraging external knowledge within machine/deep learning solutions, with the potential benefits for interpretability, explainability, robustness, and transferability. In this tutorial, we will examine the use of knowledge-infused learning for three core state-of-the-art technical achievements within the AD domain. With a collaborative team from both academia and industry, we will demonstrate recent innovations using real-world datasets.</p>
<p>For more information, visit <a href="https://kl4ad.github.io/2022/">the KL4AD website.</a></p>
        
<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/kirl/" target="_blank" style="text-decoration: underline;"> Knowledge-infused Reinforcement Learning </a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<p>Virtual health agents (VHAs) have received considerable attention, but the early focus has been on collecting data, helping patients follow generic health guidelines, and providing reminders for clinical appointments. While presenting the collected data and frequency of visits to the clinician is useful, further context and personalization are needed for a VHA to interpret and understand what the data means in clinical terms. This has made their use in managing health limited. Such understanding enables patient empowerment and self-appraisal -- i.e., aiding the patient in interpreting the data to understand the changes in the patient’s health conditions, and self-management -- i.e., to help a patient better manage their health through better adherence to the clinician guidelines and clinician recommended care plan. Crisis conditions such as the current pandemic have further stressed our healthcare system and have made the need for such advanced support more attractive and in demand. Consider the rapid growth in mental health because the patients who already had mental health conditions worsen, and many develop such conditions due to the challenges arising from lockdown, isolation, and economic hardships. The severe lack of timely availability of clinical expertise to meet the rapidly growing demand provides the motivation for advancing this research in developing more advanced VHAs and evaluating it in the context of mental health management.</p>
<p>For more information, visit <a href="https://aiisc.ai/kirl/">the KiRL website.</a></p>
	  
<iframe width="560" height="315" src="https://www.youtube.com/embed/iVx_3uBJQRk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/xaikg/" target="_blank" style="text-decoration: underline;"> Explainable AI using Knowledge Graphs </a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<h5 style="margin:3% 0;color:#d9232d;"><strong>Date: January 02 - 04, 2021, Bangalore, India</strong></h5>
<p>During the last decade, traditional data-driven deep learning (DL) has shown remarkable success in essential natural language processing tasks, such as relation extraction. Yet, challenges remain in developing artificial intelligence (AI) methods in real-world cases that require explainability through human interpretable and traceable outcomes. The scarcity of labeled data for downstream supervised tasks and entangled embeddings produced as an outcome of self-supervised pre-training objectives also hinders interpretability and explainability. Additionally, data labeling in multiple unstructured domains, particularly healthcare and education, is computationally expensive as it requires a pool of human expertise. Consider Education Technology, where AI systems fall along a “capability spectrum” depending on how extensively they exploit various resources, such as academic content, granularity in student engagement, academic domain experts, and knowledge bases to identify concepts that would help achieve knowledge mastery for student goals. Likewise, the task of assessing human health using online conversations raises challenges for current statistical DL methods through evolving cultural and context-specific discussions. Hence, developing strategies that merge AI with stratified knowledge to identify concepts that would delineate healthcare conversations patterns and help healthcare professionals decide. Such technological innovations are imperative as they provide consistency and explainability in outcomes. This tutorial discusses the notion of explainability and interpretability through the use of knowledge graphs in (1) Healthcare on the Web, (2) Education Technology. This tutorial will provide details of knowledge-infused learning algorithms and its contribution to explainability for the above two applications that can be applied to any other domain using knowledge graphs. </p>
<p>For more information, visit <a href="https://aiisc.ai/xaikg/">https://aiisc.ai/xaikg/</a></p>

<div class="embed-responsive embed-responsive-16by9 youtube">
    <iframe class="youtube-frame" src="https://www.youtube.com/embed/f1sahXYDjRI" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>

  <h3 style="margin:3% 0;color:#d9232d;"><a href="http://kidl2020.aiisc.ai/" target="_blank" style="text-decoration: underline;" > ACM HT 2020 Tutorial: Knowledge-infused Deep Learning</a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
  <p>Recent advances in statistical and data-driven deep learning demonstrate significant success in natural language understanding without using prior knowledge, especially in structured and generic domains, where data is abundant. On the other hand, in text processing problems that are dynamic and impact the society at large, existing data-dependent, state-of-the-art deep learning methods remain vulnerable to veracity considerations and especially, high volume that masks small, emergent signals. Statistical natural language processing methods have shown poor performance in capturing: (1) Human well being online especially in evolving events (e.g. mental health communications on Reddit, Twitter), (2) Culture and context specific discussion on the web (e.g. humor detection, extremism on social media), (3) Social Network Analysis (help-seeker and care-provider) during pandemic or disaster scenarios, and (4) Explainable methods of learning that drive technological innovations and inventions for community betterment. In such social hypertext, leveraging the semantic-web concept of knowledge graphs is a promising approach to the enhancement of deep learning and natural language processing.</p>
  <p>According to Piagetian human learning theory, the activation of existing schema guides the apprehension of experience to support the generation of context sensitive responses. Activating prior knowledge connects current and past experience for identifying relations, supporting explanation, reducing ambiguity, structuring new knowledge, and application to novel materials. Further, human learning does not necessarily rely on large amounts of (annotated) cases to proceed. Because prior knowledge is so powerful in human learning, its incorporation at various levels of abstraction in deep learning could benefit outcomes. Example the desiderata include compensating for data limitations, improving inductive bias, generating explainable outcomes and enabling trust. These are particularly useful for data-limited but otherwise complex, evolving problems in domains such as mental healthcare, online social threats and epidemic/pandemic.</p>
  <p>Despite the general agreement that structured prior knowledge and tacit knowledge (the inferred outcome of a model) resulting from deep learning should be combined, there has been little progress. Recent debates on Neuro-Symbolic AI , the inclusion of innate priors in deep learning, and AI fireside chat have identified knowledge-infused learning to improve explainability, interpretability, and trust in AI systems.</p>
  <p>In this tutorial, we take use cases from the aforementioned two social good applications (Mental Health, Radicalization) and multimodal aspects of social media (e.g. scene understanding from images, video and text (hypermedia/hypertext) often found in documentation of critical events to explore the modern aspect of hypertext using semantic web in the form of Knowledge Graphs (KG). Specifically, the tutorial will provide a detailed walkthrough on Knowledge Graphs and their utility in developing knowledge-infusion techniques for interpretable and explainable learning for text, video, images, and graphical data on the web with the following agenda: Motivate the novel paradigm of knowledge-infused learning using computational learning and cognitive theories. Describe the different forms of knowledge, methods of automatic modeling of KG, and infusion methods in deep/machine learning. Discuss application-specific evaluation methods specifically for explainability and reasoning using benchmark datasets and knowledge-resources that show promise in advancing the capabilities of deep learning. Future directions of KGs and robust learning for the Web and Society.</p>
  
  <div class="embed-responsive embed-responsive-16by9 youtube">
    <iframe class="youtube-frame" src="https://www.youtube.com/embed/j_fWP4ZTL4o" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>

<h3 style="margin:3% 0;color:#d9232d;"> <a href="https://aiisc.ai/kiwo-icwsm/" target="_blank" style="text-decoration: underline;"> Knowledge In - Wisdom Out - Explainable Data for AI in Cyber Social Threats and Public Health </a> <i class='bx bx-link' style="font-size: 20px;" ></i></h3>
<h5 style="margin:3% 0;color:#d9232d;"><strong>Date: June 07 - 10, 2021</strong></h5>

<p>
 In today's data-driven world, organizations derive insights from massive amounts of data through large scale statistical machine learning models. However, statistical techniques can be easy to fool with adversarial instances (a neural network can predict a non-extremist as an extremist by mere presence of the word Jihad), which raises question in Data Quality. In high stakes decision making problems, such as cyber social threats, it is highly sensitive to classify a non-extremist as an extremist and vice-versa. Data quality is good if the data possesses adequate domain coverage and the labels contain adequate semantics. For example, is the semantics of an extremist vs. non-extremist vis-a-vis the word Jihad captured in the label (adequate semantics in labels)? Also, are there enough non-extremists with the word Jihad in the training data from the perspective of religion, hate, or ideology? Thus semantic annotation of the data, beyond mere labels attached to data instances, can significantly improve the robustness of model outcomes and ensure that the model has learned from trustworthy, knowledge-guided data standards. It is important to note that the knowledge-guided standards help de-bias the data if specified correctly (contextualized de-biasing extremist behavior data from bias towards the word Jihad). Therefore, in addition to trust in the robustness of outcomes, knowledge guided data creation also enables fair and ethical practices during real-world deployment of machine learning in high stakes decision making. We denote such data as Explainable Data. In this tutorial of type <span style="text-decoration: underline;">course and case-studies</span>, we detail how to construct <b>Explainable Data</b> using various expert resources and knowledge graphs. All the materials (resources and implementations) presented during the tutorial will be made available on:<a href="https://aiisc.ai/kiwo-icwsm"> KIWO-ICWSM</a>, a week before the tutorial. We plan a 90 minute tutorial (Intermediate Level) with 2 breaks (5 mins each).
</p>
<br>	


<div class="embed-responsive embed-responsive-16by9 youtube">
  <iframe class="youtube-frame" width="900" height="506" src="https://www.youtube.com/embed/NHTSm5TW7E0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
  	<br>	
  	<br>	

</div>

<script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>
  <script src="assets/js/main.js"></script>
</body>
</html>

<script>
  document.addEventListener("DOMContentLoaded", function() {
    var header = document.getElementById("header");
    var screen = document.getElementById("screen");
    if (header && screen) {
        // Get the height of the header without extra padding or margin
        var headerHeight = header.getBoundingClientRect().height;
        screen.style.marginTop = headerHeight + "px"; // Add space only for the header height
    }
  });
</script>